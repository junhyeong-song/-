! git clone https://github.com/NeuralOperator/neuraloperator
! pip install  ./neuraloperator
! pip install -r ./neuraloperator/requirements.txt

# no need to restart the colab

from neuralop.layers.coda_blocks import CODABlocks

import torch
import torch.nn as nn
import torch.nn.functional as F
from einops import rearrange
class SimpleModel(nn.Module):
    def __init__(self,
                 variable_codim,
                 hidden_dim,
                 n_layers):
        super().__init__()

        '''
        variable_codim: it is the number of channels for each varible + number of channels for variable encoding.
        hidden_dim: input will be projected to variable_codim --> hidden_din by lifting layer
        '''

        self.variable_codim = variable_codim
        self.hidden_dim = hidden_dim
        self.lifting = nn.Conv2d(variable_codim, hidden_dim, kernel_size=1)
        self.module_list = nn.ModuleList()
        for _ in range(n_layers):
            self.module_list.append(CODABlocks(
                                        n_modes=[25,25],
                                        n_heads=1,
                                        norm='instance_norm',
                                        token_codimension=self.hidden_dim//4,
                                        per_channel_attention=False,
                                        permutation_eq=True,
                                        nonlinear_attention=True,
                                        scale=1)
                                    )

        self.projection = nn.Conv2d(hidden_dim, 1, kernel_size=1) # I am assuming each output variable consists of 1 channel

    def forward(self, x):
        batch = x.shape[0]

        # permutation equivarinat lifting operation
        xp = rearrange(x, 'b (c d) h w -> (b c) d h w ', d = self.variable_codim)
        xp = self.lifting(xp)
        x = rearrange(xp, '(b c) d h w -> b (c d) h w', b=batch)

        # pad x
        x = F.pad(x, (20, 20, 20, 20), mode='constant')

        # attention
        for module in self.module_list:
            x = module(x)

        # unpad
        x = x[:, :, 20:-20, 20:-20]

        # permutation equivarinat projection
        xp = rearrange(x, 'b (c d) h w -> (b c) d h w ', d = self.hidden_dim)
        xp = self.projection(xp)
        x = rearrange(xp, '(b c) d h w -> b (c d) h w', b=batch)
        return x

class VariableEncoding2d(nn.Module):
    def __init__(self,
                 n_channel,
                 modes) -> None:
        super().__init__()
        self.modes = modes
        # Fourier Coifficients
        self.coefficients_r = nn.Parameter(
            torch.empty(1, n_channel, *modes))
        self.coefficients_i = nn.Parameter(
            torch.empty(1, n_channel, *modes))
        self.reset_parameters()
        self.transform = torch.fft.ifft2


    def reset_parameters(self):
        std = (1 / (self.modes[-1] * self.modes[-2]))**0.5
        torch.nn.init.normal_(self.coefficients_r, mean=0.0, std=std)
        torch.nn.init.normal_(self.coefficients_i, mean=0.0, std=std)

    def forward(self, x):
        """Takes a input and outputs the positional encodings for same resolution"""

        size_x, size_y = x.shape[-2], x.shape[-1]

        return self.transform(
                self.coefficients_r + 1.0j * self.coefficients_i,
                s=(size_x, size_y)
            ).real.repeat(x.shape[0], 1, 1, 1)

var_x = torch.randn(40, 1, 64, 64)  # x_t
var_y = torch.randn(40, 1, 64, 64)  # y_t

tar_x = torch.randn(40, 1,  64, 64) # x_{t+1}
tar_y = torch.randn(40, 1,  64, 64) # y_{t+1}

import torch.utils.data as data

tensor_dataset = data.TensorDataset(var_x, var_y, tar_x, tar_y)
dataloader = data.DataLoader(tensor_dataset, batch_size=10, shuffle=True)

# using positional encoding with 2 channels
var_en_1 , var_en_2 = VariableEncoding2d(2, (20,20)), VariableEncoding2d(2, (20,20))

codano_model = SimpleModel(
    variable_codim=3, # (each variable consists of 1 channel) + (positional encoding for each variable) =  1+2
    hidden_dim=32,
    n_layers=4
)


codano_model = codano_model.cuda()
var_en_1 = var_en_1.cuda()
var_en_2 = var_en_2.cuda()
optimizer = torch.optim.Adam( list(codano_model.parameters()) +\
                              list(var_en_1.parameters()) +\
                             list(var_en_2.parameters()), lr=0.001)
for ep in range(100):
    for i in dataloader:
        optimizer.zero_grad()
        x_in, y_in, x_tar, y_tar = i
        x_in, y_in, x_tar, y_tar = x_in.cuda(), y_in.cuda(), x_tar.cuda(), y_tar.cuda()
        var_en_x, var_en_y = var_en_1(x_in), var_en_2(y_in)

        input = torch.cat((x_in, var_en_x, y_in, var_en_y), dim=1)
        output = codano_model(input)

        loss = torch.mean((output - torch.cat((x_tar, y_tar), dim=1))**2)
        loss.backward()
        optimizer.step()
        del x_in, y_in, x_tar, y_tar, var_en_x, var_en_y, input, output
        print("current loss: ", loss.item())



# data set with 3 varibales

var_x = torch.randn(40, 1, 64, 64)
var_y = torch.randn(40, 1, 64, 64)
var_z = torch.randn(40, 1, 64, 64)

tar_x = torch.randn(40, 1,  64, 64)
tar_y = torch.randn(40, 1,  64, 64)
tar_z = torch.randn(40, 1,  64, 64)


tensor_dataset_new = data.TensorDataset(var_x, var_y, var_z, tar_x, tar_y, tar_z)
dataloader_new = data.DataLoader(tensor_dataset_new, batch_size=10, shuffle=True)

# create varibale encoding only for the new physical varibale z
var_en_3 = VariableEncoding2d(2, (12,12))
var_en_3 = var_en_3.cuda()


optimizer = torch.optim.Adam( list(codano_model.parameters()) +\
                              list(var_en_1.parameters()) +\
                             list(var_en_2.parameters()) +\
                             list(var_en_3.parameters()), lr=0.001)
for ep in range(5):
    for i in dataloader_new:
        optimizer.zero_grad()
        x_in, y_in, z_in, x_tar, y_tar, z_tar = i
        x_in, y_in, z_in, x_tar, y_tar, z_tar = x_in.cuda(), y_in.cuda(), z_in.cuda(), x_tar.cuda(), y_tar.cuda(), z_tar.cuda()
        var_en_x, var_en_y, var_en_z = var_en_1(x_in), var_en_2(y_in), var_en_3(z_in)
        input = torch.cat((x_in, var_en_x, y_in, var_en_y, z_in, var_en_z), dim=1)
        output = codano_model(input)
        loss = torch.mean((output - torch.cat((x_tar, y_tar, z_tar), dim=1))**2)
        loss.backward()
        optimizer.step()
        print("current loss: ", loss.item())
